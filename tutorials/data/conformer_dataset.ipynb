{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a dataset for protein binders using a 3D representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial shows how to create a dataset for protein binders. We want to represent 3D features of different conformers of the molecule, but there are many different conformers for a given molecules. So, we extract a set of conformers and consider their Boltzmann weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Django"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [19:27:06] Enabling RDKit 2019.09.1 jupyter extensions\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import django\n",
    "\n",
    "import sys\n",
    "\n",
    "# Make sure htvs/djangochem is in your path!\n",
    "sys.path.insert(0, \"/home/saxelrod/htvs\")\n",
    "sys.path.insert(0, \"/home/saxelrod/htvs/djangochem\")\n",
    "\n",
    "os.environ[\"DJANGO_SETTINGS_MODULE\"]=\"djangochem.settings.orgel\"\n",
    "\n",
    "\n",
    "django.setup()\n",
    "\n",
    "# Shell Plus Model Imports\n",
    "from features.models import AtomDescriptor, BondDescriptor, ConnectivityMatrix, DistanceMatrix, Fingerprint, ProximityMatrix, SpeciesDescriptor, TrainingSet, Transformation\n",
    "from guardian.models import GroupObjectPermission, UserObjectPermission\n",
    "from django.contrib.contenttypes.models import ContentType\n",
    "from neuralnet.models import ActiveLearningLoop, NetArchitecture, NetCommunity, NetFamily, NeuralNetwork, NnPotential, NnPotentialStats\n",
    "from jobs.models import Job, JobConfig, WorkBatch\n",
    "from django.contrib.admin.models import LogEntry\n",
    "from django.contrib.auth.models import Group, Permission, User\n",
    "from django.contrib.sessions.models import Session\n",
    "from pgmols.models import (AtomBasis, BasisSet, Batch, Calc, Cluster,\n",
    "                           Geom, Hessian, Jacobian, MDFrame, Mechanism, Method, Mol, MolGroupObjectPermission,\n",
    "                           MolSet, MolUserObjectPermission, PathImage, ProductLink, ReactantLink, Reaction,\n",
    "                           ReactionPath, ReactionType, SinglePoint, Species, Stoichiometry, Trajectory)\n",
    "# Shell Plus Django Imports\n",
    "from django.core.cache import cache\n",
    "from django.db import transaction\n",
    "from django.utils import timezone\n",
    "from django.contrib.auth import get_user_model\n",
    "from django.urls import reverse\n",
    "from django.conf import settings\n",
    "from django.db.models import Avg, Case, Count, F, Max, Min, Prefetch, Q, Sum, When, Exists, OuterRef, Subquery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MMFF94\n",
    "\n",
    "Get a dataset of potential covid binders where the conformers are generated with mmff94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralnet.utils.nff import create_bind_dataset\n",
    "\n",
    "group_name = 'covid'\n",
    "method_name = 'molecular_mechanics_mmff94'\n",
    "method_descrip = 'MMFF conformer.'\n",
    "molsets = ['run']\n",
    "nbrlist_cutoff = 5.0\n",
    "batch_size = 10\n",
    "num_workers = 2\n",
    "# maximum conformers per species\n",
    "geoms_per_spec = 10\n",
    "\n",
    "dataset, loader = create_bind_dataset(group_name=group_name,\n",
    "                    method_name=method_name,\n",
    "                    method_descrip=method_descrip,\n",
    "                    geoms_per_spec=geoms_per_spec,\n",
    "                    nbrlist_cutoff=nbrlist_cutoff,\n",
    "                    batch_size=batch_size,\n",
    "                    num_workers=num_workers,\n",
    "                    molsets=molsets)\n",
    "\n",
    "dataset.save('covid_mmff94.pth.tar')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crest\n",
    "Same, but with crest (much better!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralnet.utils.nff import create_bind_dataset\n",
    "\n",
    "\n",
    "\n",
    "method_name = 'gfn2-xtb'\n",
    "method_descrip = 'Crest GFN2-xTB'\n",
    "\n",
    "dataset, loader = create_bind_dataset(group_name=group_name,\n",
    "                    method_name=method_name,\n",
    "                    method_descrip=method_descrip,\n",
    "                    geoms_per_spec=geoms_per_spec,\n",
    "                    nbrlist_cutoff=nbrlist_cutoff,\n",
    "                    batch_size=batch_size,\n",
    "                    num_workers=num_workers,\n",
    "                    molsets=molsets)\n",
    "\n",
    "dataset.save('covid_crest.pth.tar')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the dataset itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'weights': tensor([0.1814, 0.1683, 0.1215, 0.0636, 0.0582, 0.1142, 0.0527, 0.0517, 0.1492,\n",
      "        0.0393]), 'bind': tensor(0), 'mol_size': tensor(43), 'num_atoms': tensor(430), 'spec_id': tensor(6631940), 'nxyz': tensor([[ 6.0000,  4.3809,  1.0873,  0.1777],\n",
      "        [ 6.0000,  3.8217,  0.4284, -0.9035],\n",
      "        [ 6.0000,  2.4735,  0.5657, -1.1796],\n",
      "        ...,\n",
      "        [ 1.0000, -1.0070, -2.4155,  1.4414],\n",
      "        [ 1.0000, -3.3377, -2.3545,  2.2281],\n",
      "        [ 1.0000, -5.0852, -1.3165,  0.8359]]), 'smiles': 'c1ccc(CC(c2ccccc2)N2CCCCC2)cc1', 'nbr_list': tensor([[  0,   1],\n",
      "        [  0,   2],\n",
      "        [  0,   3],\n",
      "        ...,\n",
      "        [429, 394],\n",
      "        [429, 427],\n",
      "        [429, 428]])}\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each item in the dataset corresponds to one species. It has the number of atoms (`num_atoms`), whether it's a binder (`bind`), its smiles, the database IDs of its conformer geoms, the database ID of the species. It also has `mol_size`, the actual number of atoms in one molecule, which will allow us to separate the big nxyz (a stacked tensor consisting of all conformer nxyz's) into its conformers when needed. `weights` is a list of Boltzmann weights fo reach conformer. `nbr_list` tells you the neighbors of each atom, which takes into account the fact that ever 43 atoms you're actually in a different molecule.\n",
    "\n",
    "Let's next look at batching:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'weights': tensor([1.8140e-01, 1.6827e-01, 1.2152e-01, 6.3598e-02, 5.8217e-02, 1.1422e-01,\n",
      "        5.2662e-02, 5.1665e-02, 1.4919e-01, 3.9260e-02, 8.2947e-01, 1.6617e-01,\n",
      "        1.4203e-03, 1.4003e-03, 6.4012e-04, 5.2009e-04, 5.0009e-05, 2.0004e-05,\n",
      "        2.4004e-04, 7.0013e-05, 3.5503e-01, 2.4643e-01, 1.2268e-01, 8.3726e-02,\n",
      "        5.5241e-02, 5.5166e-02, 2.6927e-02, 2.2071e-02, 1.7791e-02, 1.4941e-02,\n",
      "        4.1169e-01, 5.3856e-01, 1.8871e-02, 1.9101e-03, 2.7221e-02, 2.1001e-04,\n",
      "        2.4001e-04, 2.3001e-04, 1.0200e-03, 5.0002e-05, 1.7496e-01, 9.2255e-02,\n",
      "        9.3527e-02, 4.0222e-02, 2.5229e-01, 6.6510e-02, 1.2409e-01, 2.7637e-02,\n",
      "        7.9095e-02, 4.9412e-02, 9.3817e-01, 1.2143e-02, 4.3072e-02, 3.9211e-03,\n",
      "        2.1006e-04, 1.2303e-03, 7.8022e-04, 2.2006e-04, 1.9005e-04, 6.0017e-05,\n",
      "        1.2285e-01, 3.9031e-02, 3.2004e-01, 1.7916e-01, 6.9935e-02, 3.5137e-02,\n",
      "        3.4967e-02, 6.6633e-02, 9.8044e-02, 3.4205e-02, 3.3080e-01, 1.6296e-01,\n",
      "        8.2121e-02, 6.5205e-02, 1.0877e-01, 5.1998e-02, 4.3292e-02, 8.2819e-02,\n",
      "        3.6772e-02, 3.5266e-02, 9.6837e-01, 3.1630e-02, 4.5464e-01, 2.5412e-01,\n",
      "        7.1440e-02, 5.8750e-02, 4.4168e-02, 3.2595e-02, 2.6250e-02, 2.4193e-02,\n",
      "        2.0198e-02, 1.3642e-02]), 'bind': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'mol_size': tensor([43, 24, 24, 43, 43, 75, 28, 44, 24, 23]), 'num_atoms': tensor([430, 240, 240, 430, 430, 750, 280, 440,  48, 230]), 'spec_id': tensor([6631940, 6631942, 6631944, 6631949, 6631955, 6631958, 6631963, 6631972,\n",
      "        6631975, 6631982]), 'nxyz': tensor([[ 6.0000,  4.3809,  1.0873,  0.1777],\n",
      "        [ 6.0000,  3.8217,  0.4284, -0.9035],\n",
      "        [ 6.0000,  2.4735,  0.5657, -1.1796],\n",
      "        ...,\n",
      "        [ 1.0000,  0.0063,  1.5642,  1.4408],\n",
      "        [ 1.0000,  2.4189,  0.5911,  1.5163],\n",
      "        [ 1.0000,  2.0578,  0.8583, -1.2571]]), 'smiles': ['c1ccc(CC(c2ccccc2)N2CCCCC2)cc1', 'CC(=O)N1CCN(C)CC1', 'OC[C@H]1NC[C@@H](O)[C@@H](O)[C@@H]1O', 'CC(C)(C)n1nc(-c2cccc3ccccc23)c2c(N)ncnc21', 'CCCn1c(=O)c2nc(-c3ccccc3)[nH]c2n(CCC)c1=O', 'CC(=O)O[C@@]12CO[C@@H]1C[C@H](O)[C@@]1(C)C(=O)[C@H](O)C3=C(C)[C@@H](O)C[C@@](O)([C@@H](OC(=O)c4ccccc4)[C@@H]12)C3(C)C', 'CC(=N)NCc1cccc(CN)c1', 'c1ccc2sc(N3CCN(Cc4ccc5c(c4)OCO5)CC3)nc2c1', 'c1ccc2oc(C3=NCCN3)cc2c1', 'OC[C@H]1O[C@H](O)C[C@@H](O)[C@@H]1O'], 'nbr_list': tensor([[   0,    1],\n",
      "        [   0,    2],\n",
      "        [   0,    3],\n",
      "        ...,\n",
      "        [3517, 3514],\n",
      "        [3517, 3515],\n",
      "        [3517, 3516]])}\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks the exact same as a regular batch, if we assumed that each smiles really had one giant xyz."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:neuralff]",
   "language": "python",
   "name": "neuralff"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
