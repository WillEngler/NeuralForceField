{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a dataset for protein binders using a 3D representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial shows how to create a dataset for protein binders. We want to represent 3D features of different conformers of the molecule, but there are many different conformers for a given molecules. So, we extract a set of conformers and consider their Boltzmann weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Django"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [13:42:57] Enabling RDKit 2019.09.1 jupyter extensions\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import django\n",
    "\n",
    "import sys\n",
    "\n",
    "# Make sure htvs/djangochem is in your path!\n",
    "sys.path.insert(0, \"/home/saxelrod/htvs\")\n",
    "sys.path.insert(0, \"/home/saxelrod/htvs/djangochem\")\n",
    "\n",
    "os.environ[\"DJANGO_SETTINGS_MODULE\"]=\"djangochem.settings.orgel\"\n",
    "\n",
    "\n",
    "django.setup()\n",
    "\n",
    "# Shell Plus Model Imports\n",
    "from features.models import AtomDescriptor, BondDescriptor, ConnectivityMatrix, DistanceMatrix, Fingerprint, ProximityMatrix, SpeciesDescriptor, TrainingSet, Transformation\n",
    "from guardian.models import GroupObjectPermission, UserObjectPermission\n",
    "from django.contrib.contenttypes.models import ContentType\n",
    "from neuralnet.models import ActiveLearningLoop, NetArchitecture, NetCommunity, NetFamily, NeuralNetwork, NnPotential, NnPotentialStats\n",
    "from jobs.models import Job, JobConfig, WorkBatch\n",
    "from django.contrib.admin.models import LogEntry\n",
    "from django.contrib.auth.models import Group, Permission, User\n",
    "from django.contrib.sessions.models import Session\n",
    "from pgmols.models import (AtomBasis, BasisSet, Batch, Calc, Cluster,\n",
    "                           Geom, Hessian, Jacobian, MDFrame, Mechanism, Method, Mol, MolGroupObjectPermission,\n",
    "                           MolSet, MolUserObjectPermission, PathImage, ProductLink, ReactantLink, Reaction,\n",
    "                           ReactionPath, ReactionType, SinglePoint, Species, Stoichiometry, Trajectory)\n",
    "# Shell Plus Django Imports\n",
    "from django.core.cache import cache\n",
    "from django.db import transaction\n",
    "from django.utils import timezone\n",
    "from django.contrib.auth import get_user_model\n",
    "from django.urls import reverse\n",
    "from django.conf import settings\n",
    "from django.db.models import Avg, Case, Count, F, Max, Min, Prefetch, Q, Sum, When, Exists, OuterRef, Subquery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MMFF94\n",
    "\n",
    "Get a dataset of potential covid binders where the conformers are generated with mmff94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralnet.utils.nff import create_bind_dataset\n",
    "\n",
    "group_name = 'covid'\n",
    "method_name = 'molecular_mechanics_mmff94'\n",
    "method_descrip = 'MMFF conformer.'\n",
    "molsets = ['run']\n",
    "nbrlist_cutoff = 5.0\n",
    "batch_size = 10\n",
    "num_workers = 2\n",
    "# maximum conformers per species\n",
    "geoms_per_spec = 10\n",
    "# geoms_per_spec = 1\n",
    "\n",
    "\n",
    "dataset, loader = create_bind_dataset(group_name=group_name,\n",
    "                    method_name=method_name,\n",
    "                    method_descrip=method_descrip,\n",
    "                    geoms_per_spec=geoms_per_spec,\n",
    "                    nbrlist_cutoff=nbrlist_cutoff,\n",
    "                    batch_size=batch_size,\n",
    "                    num_workers=num_workers,\n",
    "                    molsets=molsets)\n",
    "\n",
    "dataset.save('covid_mmff94.pth.tar')\n",
    "# dataset.save('covid_mmff94_1_geom.pth.tar')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(394)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nff.data import Dataset\n",
    "# dataset = Dataset.from_file('covid_mmff94_1_geom.pth.tar')\n",
    "dataset = Dataset.from_file('covid_mmff94.pth.tar')\n",
    "dataset.props['bind'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crest\n",
    "The same, but with Crest. Crest is a program that combines advanced sampling methods lke metadynamics with optimizations to obtain different meta-stable conformers. It also analyzes symmetry to give the degeneracy of each conformer, and combines this with the Boltzmann factor of the conformer to give its total population. It uses XTB (semi-empirical tight-binding DFT) as the force field, which is significantly more accurate than MMFF94."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralnet.utils.nff import create_bind_dataset\n",
    "import pdb\n",
    "\n",
    "group_name = 'covid'\n",
    "method_name = 'gfn2-xtb'\n",
    "method_descrip = 'Crest GFN2-xTB'\n",
    "molsets = ['run']\n",
    "nbrlist_cutoff = 5.0\n",
    "batch_size = 10\n",
    "num_workers = 2\n",
    "# maximum conformers per species\n",
    "geoms_per_spec = 10\n",
    "# geoms_per_spec = 1\n",
    "\n",
    "\n",
    "dataset, loader = create_bind_dataset(group_name=group_name,\n",
    "                    method_name=method_name,\n",
    "                    method_descrip=method_descrip,\n",
    "                    geoms_per_spec=geoms_per_spec,\n",
    "                    nbrlist_cutoff=nbrlist_cutoff,\n",
    "                    batch_size=batch_size,\n",
    "                    num_workers=num_workers,\n",
    "                    molsets=molsets)\n",
    "\n",
    "dataset.save('covid_crest.pth.tar')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the dataset itself.\n",
    "\n",
    "Number of positive binders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(139)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.props['bind'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Length of dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2592\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First species in the dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nxyz': tensor([[ 6.0000,  4.3809,  1.0873,  0.1777],\n",
      "        [ 6.0000,  3.8217,  0.4284, -0.9035],\n",
      "        [ 6.0000,  2.4735,  0.5657, -1.1796],\n",
      "        ...,\n",
      "        [ 1.0000, -1.0070, -2.4155,  1.4414],\n",
      "        [ 1.0000, -3.3377, -2.3545,  2.2281],\n",
      "        [ 1.0000, -5.0852, -1.3165,  0.8359]]), 'bind': tensor(0), 'weights': tensor([0.1814, 0.1683, 0.1215, 0.0636, 0.0582, 0.1142, 0.0527, 0.0517, 0.1492,\n",
      "        0.0393]), 'spec_id': tensor(6631940), 'num_atoms': tensor(430), 'mol_size': tensor(43), 'smiles': 'c1ccc(CC(c2ccccc2)N2CCCCC2)cc1', 'nbr_list': tensor([[  0,   1],\n",
      "        [  0,   2],\n",
      "        [  0,   3],\n",
      "        ...,\n",
      "        [429, 394],\n",
      "        [429, 427],\n",
      "        [429, 428]])}\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each item in the dataset corresponds to one species. It has the number of atoms (`num_atoms`), whether it's a binder (`bind`), its smiles, the database IDs of its conformer geoms, the database ID of the species. It also has `mol_size`, the actual number of atoms in one molecule, which will allow us to separate the big nxyz (a stacked tensor consisting of all conformer nxyz's) into its conformers when needed. `weights` is a list of Boltzmann weights fo reach conformer. `nbr_list` tells you the neighbors of each atom, which takes into account the fact that ever 43 atoms you're actually in a different molecule.\n",
    "\n",
    "Let's next look at batching:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nxyz': tensor([[ 6.0000,  4.3809,  1.0873,  0.1777],\n",
      "        [ 6.0000,  3.8217,  0.4284, -0.9035],\n",
      "        [ 6.0000,  2.4735,  0.5657, -1.1796],\n",
      "        ...,\n",
      "        [ 1.0000,  0.0063,  1.5642,  1.4408],\n",
      "        [ 1.0000,  2.4189,  0.5911,  1.5163],\n",
      "        [ 1.0000,  2.0578,  0.8583, -1.2571]]), 'bind': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'weights': tensor([1.8140e-01, 1.6827e-01, 1.2152e-01, 6.3598e-02, 5.8217e-02, 1.1422e-01,\n",
      "        5.2662e-02, 5.1665e-02, 1.4919e-01, 3.9260e-02, 8.2947e-01, 1.6617e-01,\n",
      "        1.4203e-03, 1.4003e-03, 6.4012e-04, 5.2009e-04, 5.0009e-05, 2.0004e-05,\n",
      "        2.4004e-04, 7.0013e-05, 3.5503e-01, 2.4643e-01, 1.2268e-01, 8.3726e-02,\n",
      "        5.5241e-02, 5.5166e-02, 2.6927e-02, 2.2071e-02, 1.7791e-02, 1.4941e-02,\n",
      "        4.1169e-01, 5.3856e-01, 1.8871e-02, 1.9101e-03, 2.7221e-02, 2.1001e-04,\n",
      "        2.4001e-04, 2.3001e-04, 1.0200e-03, 5.0002e-05, 1.7496e-01, 9.2255e-02,\n",
      "        9.3527e-02, 4.0222e-02, 2.5229e-01, 6.6510e-02, 1.2409e-01, 2.7637e-02,\n",
      "        7.9095e-02, 4.9412e-02, 9.3817e-01, 1.2143e-02, 4.3072e-02, 3.9211e-03,\n",
      "        2.1006e-04, 1.2303e-03, 7.8022e-04, 2.2006e-04, 1.9005e-04, 6.0017e-05,\n",
      "        1.2285e-01, 3.9031e-02, 3.2004e-01, 1.7916e-01, 6.9935e-02, 3.5137e-02,\n",
      "        3.4967e-02, 6.6633e-02, 9.8044e-02, 3.4205e-02, 3.3080e-01, 1.6296e-01,\n",
      "        8.2121e-02, 6.5205e-02, 1.0877e-01, 5.1998e-02, 4.3292e-02, 8.2819e-02,\n",
      "        3.6772e-02, 3.5266e-02, 9.6837e-01, 3.1630e-02, 4.5464e-01, 2.5412e-01,\n",
      "        7.1440e-02, 5.8750e-02, 4.4168e-02, 3.2595e-02, 2.6250e-02, 2.4193e-02,\n",
      "        2.0198e-02, 1.3642e-02]), 'spec_id': tensor([6631940, 6631942, 6631944, 6631949, 6631955, 6631958, 6631963, 6631972,\n",
      "        6631975, 6631982]), 'num_atoms': tensor([430, 240, 240, 430, 430, 750, 280, 440,  48, 230]), 'mol_size': tensor([43, 24, 24, 43, 43, 75, 28, 44, 24, 23]), 'smiles': ['c1ccc(CC(c2ccccc2)N2CCCCC2)cc1', 'CC(=O)N1CCN(C)CC1', 'OC[C@H]1NC[C@@H](O)[C@@H](O)[C@@H]1O', 'CC(C)(C)n1nc(-c2cccc3ccccc23)c2c(N)ncnc21', 'CCCn1c(=O)c2nc(-c3ccccc3)[nH]c2n(CCC)c1=O', 'CC(=O)O[C@@]12CO[C@@H]1C[C@H](O)[C@@]1(C)C(=O)[C@H](O)C3=C(C)[C@@H](O)C[C@@](O)([C@@H](OC(=O)c4ccccc4)[C@@H]12)C3(C)C', 'CC(=N)NCc1cccc(CN)c1', 'c1ccc2sc(N3CCN(Cc4ccc5c(c4)OCO5)CC3)nc2c1', 'c1ccc2oc(C3=NCCN3)cc2c1', 'OC[C@H]1O[C@H](O)C[C@@H](O)[C@@H]1O'], 'nbr_list': tensor([[   0,    1],\n",
      "        [   0,    2],\n",
      "        [   0,    3],\n",
      "        ...,\n",
      "        [3517, 3514],\n",
      "        [3517, 3515],\n",
      "        [3517, 3516]])}\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks the exact same as a regular batch, if we assumed that each smiles really had one giant xyz. The xyz's of the individual conformers can be recovered by splitting the batch into species through `num_atoms`, and the species into conformers through `mol_size`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geometries and Boltzmann factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's check that we're really getting the right geometries and Boltzmann weights. \n",
    "- Here's the geometry of the first species with the highest Boltzmann weight:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.7000e+01,  2.8329e+00,  1.2598e+00, -2.0776e-01],\n",
      "        [ 6.0000e+00,  2.5839e+00, -1.5335e-02,  8.8423e-01],\n",
      "        [ 6.0000e+00,  2.7282e+00, -1.3414e+00,  5.2334e-01],\n",
      "        [ 6.0000e+00,  3.0365e+00, -1.8108e+00, -7.1847e-01],\n",
      "        [ 7.0000e+00, -2.1606e+00,  1.2852e+00,  3.2123e-01],\n",
      "        [ 6.0000e+00, -2.8204e+00,  1.8081e-01,  1.0101e+00],\n",
      "        [ 7.0000e+00, -2.2042e+00, -1.1064e+00,  7.0226e-01],\n",
      "        [ 6.0000e+00, -2.2666e+00, -1.3062e+00, -7.4260e-01],\n",
      "        [ 7.0000e+00, -1.5938e+00, -2.3789e-01, -1.4735e+00],\n",
      "        [ 6.0000e+00, -2.2245e+00,  1.0284e+00, -1.1142e+00],\n",
      "        [ 1.0000e+00, -1.7155e+00,  1.8397e+00, -1.6419e+00],\n",
      "        [ 1.0000e+00, -3.2734e+00,  1.0017e+00, -1.4222e+00],\n",
      "        [ 6.0000e+00, -2.0413e-01, -1.9140e-01, -1.0350e+00],\n",
      "        [ 7.0000e+00, -9.5094e-02,  3.4757e-02,  4.0284e-01],\n",
      "        [ 6.0000e+00, -7.5750e-01,  1.2957e+00,  7.1914e-01],\n",
      "        [ 1.0000e+00, -6.9661e-01,  1.4687e+00,  1.7977e+00],\n",
      "        [ 1.0000e+00, -2.4446e-01,  2.1068e+00,  1.9501e-01],\n",
      "        [ 6.0000e+00, -7.9962e-01, -1.0413e+00,  1.0900e+00],\n",
      "        [ 1.0000e+00, -3.1742e-01, -1.9915e+00,  8.4373e-01],\n",
      "        [ 1.0000e+00, -7.3740e-01, -8.7460e-01,  2.1694e+00],\n",
      "        [ 1.0000e+00,  2.8287e-01, -1.1400e+00, -1.2793e+00],\n",
      "        [ 1.0000e+00,  3.0597e-01,  6.1986e-01, -1.5612e+00],\n",
      "        [ 1.0000e+00, -1.7889e+00, -2.2587e+00, -9.8866e-01],\n",
      "        [ 1.0000e+00, -3.3156e+00, -1.3400e+00, -1.0496e+00],\n",
      "        [ 1.0000e+00, -2.7634e+00,  3.5139e-01,  2.0890e+00],\n",
      "        [ 1.0000e+00, -3.8706e+00,  1.5146e-01,  7.0673e-01],\n",
      "        [ 1.0000e+00,  3.2089e+00, -1.1401e+00, -1.5410e+00],\n",
      "        [ 1.0000e+00,  3.1269e+00, -2.8637e+00, -9.1009e-01],\n",
      "        [ 1.0000e+00,  2.5654e+00, -2.0505e+00,  1.3250e+00],\n",
      "        [ 1.0000e+00,  2.3412e+00,  2.9636e-01,  1.8840e+00]])\n"
     ]
    }
   ],
   "source": [
    "mol_size_0 = dataset.props['mol_size'][0]\n",
    "print(dataset.props['nxyz'][0][:mol_size_0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boltzmann weights: tensor([0.3742, 0.1315, 0.1294, 0.1242, 0.1064, 0.0414, 0.0352, 0.0327, 0.0251])\n",
      "Weight of first conformer relative to second most relevant one: 0.3513377010822296\n"
     ]
    }
   ],
   "source": [
    "print(\"Boltzmann weights: {}\".format(dataset.props['weights'][0]))\n",
    "weight_0 = dataset.props['weights'][0][0]\n",
    "weight_1 = dataset.props['weights'][0][1]\n",
    "\n",
    "rel_weight = weight_1 / weight_0\n",
    "\n",
    "print(\"Weight of first conformer relative to second most relevant one: {}\".format(rel_weight))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the xyz's agree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[17.0, 2.8329098101, 1.25977548, -0.207756332],\n",
       " [6.0, 2.5839438483, -0.0153345928, 0.8842313446],\n",
       " [6.0, 2.7282107936, -1.3413828894, 0.5233412086],\n",
       " [6.0, 3.0365184967, -1.8108289526, -0.7184703834],\n",
       " [7.0, -2.1605736971, 1.2852225087, 0.3212320791],\n",
       " [6.0, -2.8204120798, 0.1808104026, 1.0100835068],\n",
       " [7.0, -2.2041538319, -1.1063585857, 0.7022629139],\n",
       " [6.0, -2.2665868945, -1.3061639571, -0.7426005197],\n",
       " [7.0, -1.5938346841, -0.2378916911, -1.4734985127],\n",
       " [6.0, -2.2244888716, 1.0283553587, -1.1142249338],\n",
       " [1.0, -1.7155102191, 1.8396771585, -1.6419159547],\n",
       " [1.0, -3.2734228639, 1.0016867065, -1.4222229556],\n",
       " [6.0, -0.2041306662, -0.1913957616, -1.0350406235],\n",
       " [7.0, -0.0950937656, 0.0347572271, 0.4028420165],\n",
       " [6.0, -0.7574968951, 1.2957213008, 0.7191432874],\n",
       " [1.0, -0.6966142045, 1.4686992449, 1.7977002319],\n",
       " [1.0, -0.244463933, 2.1068296296, 0.195005402],\n",
       " [6.0, -0.7996232901, -1.041322662, 1.0900393652],\n",
       " [1.0, -0.3174208404, -1.9915033605, 0.8437347219],\n",
       " [1.0, -0.7374003673, -0.8746013897, 2.1694491679],\n",
       " [1.0, 0.282865338, -1.1400171681, -1.2793156397],\n",
       " [1.0, 0.3059688332, 0.619862117, -1.561221786],\n",
       " [1.0, -1.7888724894, -2.2586663454, -0.9886645642],\n",
       " [1.0, -3.3156215037, -1.3399972285, -1.0496408996],\n",
       " [1.0, -2.763421929, 0.3513948634, 2.0889515817],\n",
       " [1.0, -3.8705851438, 0.1514586813, 0.7067265565],\n",
       " [1.0, 3.208859794, -1.1401464932, -1.540971351],\n",
       " [1.0, 3.1269193391, -2.8636871709, -0.9100915636],\n",
       " [1.0, 2.5653614213, -2.05049392, 1.3249712498],\n",
       " [1.0, 2.3411503402, 0.2963556452, 1.8839892963]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spec = Species.objects.get(id=dataset.props['spec_id'][0])\n",
    "geoms = spec.geom_set.filter(calcs__method__name=method_name,\n",
    "                           calcs__method__description=method_descrip,\n",
    "                           calcs__props__boltzmannweight__isnull=False\n",
    "                           ).order_by(\"-calcs__props__boltzmannweight\").all()\n",
    "geom_0 = geoms[0]\n",
    "geom_1 = geoms[1]\n",
    "\n",
    "calc_0 = geom_0.calcs.filter(method__name=method_name,\n",
    "                        method__description=method_descrip).first()\n",
    "calc_1 = geom_1.calcs.filter(method__name=method_name,\n",
    "                        method__description=method_descrip).first()\n",
    "\n",
    "geom_0.xyz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the relative weights agree (the absolute ones do not, since we limited each species to a maximum of 10 conformers):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27697\n",
      "0.09731\n",
      "\n",
      "\n",
      "0.35133769000252735\n"
     ]
    }
   ],
   "source": [
    "\n",
    "weight_0 = calc_0.props['boltzmannweight']\n",
    "weight_1 = calc_1.props['boltzmannweight']\n",
    "\n",
    "print(weight_0)\n",
    "print(weight_1)\n",
    "print(\"\\n\")\n",
    "\n",
    "rel_weight = weight_1 / weight_0\n",
    "print(rel_weight)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:neuralff]",
   "language": "python",
   "name": "neuralff"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
