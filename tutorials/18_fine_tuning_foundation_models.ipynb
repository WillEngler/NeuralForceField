{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning foundation models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook reviews methods to fine-tune two large \"foundation\" models for neural network potentials: CHGNet and MACE-MP-0. The models are fine-tuned using data from a set of Crystals in the toy database. This approach relies on freezing a subset of the layers of the model and training the remaining layers on the new data. There are other fine-tuning strategies, such as training the entire model with a smaller learning rate, but this notebook focuses on the former."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "from torch.utils.data import DataLoader\n",
    "from mace.modules.models import ScaleShiftMACE\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from nff.train.transfer import freeze_parameters, unfreeze_readout\n",
    "from nff.data import Dataset, split_train_validation_test, collate_dicts\n",
    "from nff.train import Trainer, loss, hooks, metrics, evaluate\n",
    "from nff.nn.models.mace import NFFMACEWrapper, DirectNffScaleMACEWrapper\n",
    "from nff.nn.models.chgnet import CHGNetNFF\n",
    "\n",
    "DEVICE = \"cpu\"\n",
    "OUTDIR_MACE = \"./sandbox/mace\"\n",
    "OUTDIR_CHGNET = \"./sandbox/chgnet\"\n",
    "BATCH_SIZE = 1\n",
    "UNITS = {\n",
    "    \"energy_grad\": \"kcal (mol $\\mathdefault{\\AA}$)$^{\\mathdefault{-1}}$\",\n",
    "    \"energy\": \"kcal mol$^{\\mathdefault{-1}}$\",\n",
    "}\n",
    "\n",
    "if os.path.exists(OUTDIR_MACE):\n",
    "    shutil.rmtree(OUTDIR_MACE)\n",
    "    os.mkdir(OUTDIR_MACE)\n",
    "\n",
    "# The tutorial writer does not like the default font\n",
    "# so we change it to Arial\n",
    "mpl.font_manager.findSystemFonts(fontpaths=None, fontext=\"ttf\")\n",
    "mpl.font_manager.findfont(\"Arial\")\n",
    "plt.rcParams[\"figure.dpi\"] = 100\n",
    "plt.rcParams[\"font.family\"] = \"Arial\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MACE-MP-0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by loading the `MACE-MP-0` model and look at its architecture. The manuscript describing the architecture is available [here](https://proceedings.neurips.cc/paper_files/paper/2022/file/4a36c3c51af11ed9f34615b81edb5bbc-Paper-Conference.pdf). If you would like to dig into the details of the model, the appendices are available [here](https://proceedings.neurips.cc/paper_files/paper/2022/file/4a36c3c51af11ed9f34615b81edb5bbc-Supplemental-Conference.pdf).\n",
    "\n",
    "The code in the cell below assumes that you have installed `mace` in your home directory and you have downloaded the `MACE-MP-0` model (you can find instructions on installing MACE and downloading its pre-trained models using the package's built-in methods in `htvs/chemconfigs/ase/README_MACE.md`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No dtype selected, switching to float64 to match model dtype.\n"
     ]
    }
   ],
   "source": [
    "user = os.environ.get(\"USER\")\n",
    "mace_location = (\n",
    "    f\"/home/{user}/mace/mace/calculators/foundations_models/2023-12-03-mace-mp.model\"\n",
    ")\n",
    "\n",
    "# Load the MACE model with the NFF wrapper\n",
    "mace_model = DirectNffScaleMACEWrapper.from_file(mace_location, map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the architecture of the `MACE-MP-0` model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.modules of DirectNffScaleMACEWrapper(\n",
       "  (node_embedding): LinearNodeEmbeddingBlock(\n",
       "    (linear): Linear(89x0e -> 128x0e | 11392 weights)\n",
       "  )\n",
       "  (radial_embedding): RadialEmbeddingBlock(\n",
       "    (bessel_fn): BesselBasis(r_max=6.0, num_basis=10, trainable=False)\n",
       "    (cutoff_fn): PolynomialCutoff(p=5.0, r_max=6.0)\n",
       "  )\n",
       "  (spherical_harmonics): SphericalHarmonics()\n",
       "  (atomic_energies_fn): AtomicEnergiesBlock(energies=[-3.6672, -1.3321, -3.4821, -4.7367, -7.7249, -8.4056, -7.3601, -7.2846, -4.8965, 0.0000, -2.7594, -2.8140, -4.8469, -7.6948, -6.9633, -4.6726, -2.8117, -0.0626, -2.6176, -5.3905, -7.8858, -10.2684, -8.6651, -9.2331, -8.3050, -7.0490, -5.5774, -5.1727, -3.2521, -1.2902, -3.5271, -4.7085, -3.9765, -3.8862, -2.5185, 6.7669, -2.5635, -4.9380, -10.1498, -11.8469, -12.1389, -8.7917, -8.7869, -7.7809, -6.8500, -4.8910, -2.0634, -0.6396, -2.7887, -3.8186, -3.5871, -2.8804, -1.6356, 9.8467, -2.7653, -4.9910, -8.9337, -8.7356, -8.0190, -8.2515, -7.5917, -8.1697, -13.5927, -18.5175, -7.6474, -8.1230, -7.6078, -6.8503, -7.8269, -3.5848, -7.4554, -12.7963, -14.1081, -9.3549, -11.3875, -9.6219, -7.3244, -5.3047, -2.3801, 0.2495, -2.3240, -3.7300, -3.4388, -5.0629, -11.0246, -12.2656, -13.8556, -14.9331, -15.2828])\n",
       "  (interactions): ModuleList(\n",
       "    (0): RealAgnosticResidualInteractionBlock(\n",
       "      (linear_up): Linear(128x0e -> 128x0e | 16384 weights)\n",
       "      (conv_tp): TensorProduct(128x0e x 1x0e+1x1o+1x2e+1x3o -> 128x0e+128x1o+128x2e+128x3o | 512 paths | 512 weights)\n",
       "      (conv_tp_weights): FullyConnectedNet[10, 64, 64, 64, 512]\n",
       "      (linear): Linear(128x0e+128x1o+128x2e+128x3o -> 128x0e+128x1o+128x2e+128x3o | 65536 weights)\n",
       "      (skip_tp): FullyConnectedTensorProduct(128x0e x 89x0e -> 128x0e+128x1o | 1458176 paths | 1458176 weights)\n",
       "      (reshape): reshape_irreps()\n",
       "    )\n",
       "    (1): RealAgnosticResidualInteractionBlock(\n",
       "      (linear_up): Linear(128x0e+128x1o -> 128x0e+128x1o | 32768 weights)\n",
       "      (conv_tp): TensorProduct(128x0e+128x1o x 1x0e+1x1o+1x2e+1x3o -> 256x0e+384x1o+384x2e+256x3o | 1280 paths | 1280 weights)\n",
       "      (conv_tp_weights): FullyConnectedNet[10, 64, 64, 64, 1280]\n",
       "      (linear): Linear(256x0e+384x1o+384x2e+256x3o -> 128x0e+128x1o+128x2e+128x3o | 163840 weights)\n",
       "      (skip_tp): FullyConnectedTensorProduct(128x0e+128x1o x 89x0e -> 128x0e | 1458176 paths | 1458176 weights)\n",
       "      (reshape): reshape_irreps()\n",
       "    )\n",
       "  )\n",
       "  (products): ModuleList(\n",
       "    (0): EquivariantProductBasisBlock(\n",
       "      (symmetric_contractions): SymmetricContraction(\n",
       "        (contractions): ModuleList(\n",
       "          (0): Contraction(\n",
       "            (contractions_weighting): ModuleList(\n",
       "              (0-1): 2 x GraphModule()\n",
       "            )\n",
       "            (contractions_features): ModuleList(\n",
       "              (0-1): 2 x GraphModule()\n",
       "            )\n",
       "            (weights): ParameterList(\n",
       "                (0): Parameter containing: [torch.float64 of size 89x4x128]\n",
       "                (1): Parameter containing: [torch.float64 of size 89x1x128]\n",
       "            )\n",
       "            (graph_opt_main): GraphModule()\n",
       "          )\n",
       "          (1): Contraction(\n",
       "            (contractions_weighting): ModuleList(\n",
       "              (0-1): 2 x GraphModule()\n",
       "            )\n",
       "            (contractions_features): ModuleList(\n",
       "              (0-1): 2 x GraphModule()\n",
       "            )\n",
       "            (weights): ParameterList(\n",
       "                (0): Parameter containing: [torch.float64 of size 89x6x128]\n",
       "                (1): Parameter containing: [torch.float64 of size 89x1x128]\n",
       "            )\n",
       "            (graph_opt_main): GraphModule()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (linear): Linear(128x0e+128x1o -> 128x0e+128x1o | 32768 weights)\n",
       "    )\n",
       "    (1): EquivariantProductBasisBlock(\n",
       "      (symmetric_contractions): SymmetricContraction(\n",
       "        (contractions): ModuleList(\n",
       "          (0): Contraction(\n",
       "            (contractions_weighting): ModuleList(\n",
       "              (0-1): 2 x GraphModule()\n",
       "            )\n",
       "            (contractions_features): ModuleList(\n",
       "              (0-1): 2 x GraphModule()\n",
       "            )\n",
       "            (weights): ParameterList(\n",
       "                (0): Parameter containing: [torch.float64 of size 89x4x128]\n",
       "                (1): Parameter containing: [torch.float64 of size 89x1x128]\n",
       "            )\n",
       "            (graph_opt_main): GraphModule()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (linear): Linear(128x0e -> 128x0e | 16384 weights)\n",
       "    )\n",
       "  )\n",
       "  (readouts): ModuleList(\n",
       "    (0): LinearReadoutBlock(\n",
       "      (linear): Linear(128x0e+128x1o -> 1x0e | 128 weights)\n",
       "    )\n",
       "    (1): NonLinearReadoutBlock(\n",
       "      (linear_1): Linear(128x0e -> 16x0e | 2048 weights)\n",
       "      (non_linearity): Activation [x] (16x0e -> 16x0e)\n",
       "      (linear_2): Linear(16x0e -> 1x0e | 16 weights)\n",
       "    )\n",
       "  )\n",
       "  (scale_shift): ScaleShiftBlock(scale=0.804154, shift=0.164097)\n",
       "  (mace_model): ScaleShiftMACE(\n",
       "    (node_embedding): LinearNodeEmbeddingBlock(\n",
       "      (linear): Linear(89x0e -> 128x0e | 11392 weights)\n",
       "    )\n",
       "    (radial_embedding): RadialEmbeddingBlock(\n",
       "      (bessel_fn): BesselBasis(r_max=6.0, num_basis=10, trainable=False)\n",
       "      (cutoff_fn): PolynomialCutoff(p=5.0, r_max=6.0)\n",
       "    )\n",
       "    (spherical_harmonics): SphericalHarmonics()\n",
       "    (atomic_energies_fn): AtomicEnergiesBlock(energies=[-3.6672, -1.3321, -3.4821, -4.7367, -7.7249, -8.4056, -7.3601, -7.2846, -4.8965, 0.0000, -2.7594, -2.8140, -4.8469, -7.6948, -6.9633, -4.6726, -2.8117, -0.0626, -2.6176, -5.3905, -7.8858, -10.2684, -8.6651, -9.2331, -8.3050, -7.0490, -5.5774, -5.1727, -3.2521, -1.2902, -3.5271, -4.7085, -3.9765, -3.8862, -2.5185, 6.7669, -2.5635, -4.9380, -10.1498, -11.8469, -12.1389, -8.7917, -8.7869, -7.7809, -6.8500, -4.8910, -2.0634, -0.6396, -2.7887, -3.8186, -3.5871, -2.8804, -1.6356, 9.8467, -2.7653, -4.9910, -8.9337, -8.7356, -8.0190, -8.2515, -7.5917, -8.1697, -13.5927, -18.5175, -7.6474, -8.1230, -7.6078, -6.8503, -7.8269, -3.5848, -7.4554, -12.7963, -14.1081, -9.3549, -11.3875, -9.6219, -7.3244, -5.3047, -2.3801, 0.2495, -2.3240, -3.7300, -3.4388, -5.0629, -11.0246, -12.2656, -13.8556, -14.9331, -15.2828])\n",
       "    (interactions): ModuleList(\n",
       "      (0): RealAgnosticResidualInteractionBlock(\n",
       "        (linear_up): Linear(128x0e -> 128x0e | 16384 weights)\n",
       "        (conv_tp): TensorProduct(128x0e x 1x0e+1x1o+1x2e+1x3o -> 128x0e+128x1o+128x2e+128x3o | 512 paths | 512 weights)\n",
       "        (conv_tp_weights): FullyConnectedNet[10, 64, 64, 64, 512]\n",
       "        (linear): Linear(128x0e+128x1o+128x2e+128x3o -> 128x0e+128x1o+128x2e+128x3o | 65536 weights)\n",
       "        (skip_tp): FullyConnectedTensorProduct(128x0e x 89x0e -> 128x0e+128x1o | 1458176 paths | 1458176 weights)\n",
       "        (reshape): reshape_irreps()\n",
       "      )\n",
       "      (1): RealAgnosticResidualInteractionBlock(\n",
       "        (linear_up): Linear(128x0e+128x1o -> 128x0e+128x1o | 32768 weights)\n",
       "        (conv_tp): TensorProduct(128x0e+128x1o x 1x0e+1x1o+1x2e+1x3o -> 256x0e+384x1o+384x2e+256x3o | 1280 paths | 1280 weights)\n",
       "        (conv_tp_weights): FullyConnectedNet[10, 64, 64, 64, 1280]\n",
       "        (linear): Linear(256x0e+384x1o+384x2e+256x3o -> 128x0e+128x1o+128x2e+128x3o | 163840 weights)\n",
       "        (skip_tp): FullyConnectedTensorProduct(128x0e+128x1o x 89x0e -> 128x0e | 1458176 paths | 1458176 weights)\n",
       "        (reshape): reshape_irreps()\n",
       "      )\n",
       "    )\n",
       "    (products): ModuleList(\n",
       "      (0): EquivariantProductBasisBlock(\n",
       "        (symmetric_contractions): SymmetricContraction(\n",
       "          (contractions): ModuleList(\n",
       "            (0): Contraction(\n",
       "              (contractions_weighting): ModuleList(\n",
       "                (0-1): 2 x GraphModule()\n",
       "              )\n",
       "              (contractions_features): ModuleList(\n",
       "                (0-1): 2 x GraphModule()\n",
       "              )\n",
       "              (weights): ParameterList(\n",
       "                  (0): Parameter containing: [torch.float64 of size 89x4x128]\n",
       "                  (1): Parameter containing: [torch.float64 of size 89x1x128]\n",
       "              )\n",
       "              (graph_opt_main): GraphModule()\n",
       "            )\n",
       "            (1): Contraction(\n",
       "              (contractions_weighting): ModuleList(\n",
       "                (0-1): 2 x GraphModule()\n",
       "              )\n",
       "              (contractions_features): ModuleList(\n",
       "                (0-1): 2 x GraphModule()\n",
       "              )\n",
       "              (weights): ParameterList(\n",
       "                  (0): Parameter containing: [torch.float64 of size 89x6x128]\n",
       "                  (1): Parameter containing: [torch.float64 of size 89x1x128]\n",
       "              )\n",
       "              (graph_opt_main): GraphModule()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (linear): Linear(128x0e+128x1o -> 128x0e+128x1o | 32768 weights)\n",
       "      )\n",
       "      (1): EquivariantProductBasisBlock(\n",
       "        (symmetric_contractions): SymmetricContraction(\n",
       "          (contractions): ModuleList(\n",
       "            (0): Contraction(\n",
       "              (contractions_weighting): ModuleList(\n",
       "                (0-1): 2 x GraphModule()\n",
       "              )\n",
       "              (contractions_features): ModuleList(\n",
       "                (0-1): 2 x GraphModule()\n",
       "              )\n",
       "              (weights): ParameterList(\n",
       "                  (0): Parameter containing: [torch.float64 of size 89x4x128]\n",
       "                  (1): Parameter containing: [torch.float64 of size 89x1x128]\n",
       "              )\n",
       "              (graph_opt_main): GraphModule()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (linear): Linear(128x0e -> 128x0e | 16384 weights)\n",
       "      )\n",
       "    )\n",
       "    (readouts): ModuleList(\n",
       "      (0): LinearReadoutBlock(\n",
       "        (linear): Linear(128x0e+128x1o -> 1x0e | 128 weights)\n",
       "      )\n",
       "      (1): NonLinearReadoutBlock(\n",
       "        (linear_1): Linear(128x0e -> 16x0e | 2048 weights)\n",
       "        (non_linearity): Activation [x] (16x0e -> 16x0e)\n",
       "        (linear_2): Linear(16x0e -> 1x0e | 16 weights)\n",
       "      )\n",
       "    )\n",
       "    (scale_shift): ScaleShiftBlock(scale=0.804154, shift=0.164097)\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mace_model.modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has several groups of modules:\n",
    "- `node_embedding`, which is a learned representation of individual atoms (nodes) in the graph\n",
    "- `radial_embedding`, which contains Bessel functions (orthogonal functions in cylindrical coordinates, used to define message-passing directions between two neighbors; see [the DimeNet paper](https://arxiv.org/pdf/2003.03123.pdf) on which the approach is based) and a cutoff function\n",
    "- `spherical_harmonics`, which contains spherical harmonics (orthogonal functions in spherical coordinates)\n",
    "- `atomic_energies_fn`, which is a list of learned energies for each atom type that are used to compute the energy of an arrangement of atoms (molecule or crystal)\n",
    "- `interactions`, which contains two `RealAgnosticResidualInteractionBlock` modules. These modules perform the graph convolutions.\n",
    "- `products`, which contains two `EquivariantProductBasisBlock` modules that perform tensor products of the learned representations of the atoms, which are described in more detail in the appendix of the MACE paper\n",
    "- `readouts`, which converts these tensor products into our energy and force predictions.\n",
    "- `scale_shift`, which scales and shifts the energy predictions (I think).\n",
    "\n",
    "In the next section, we'll go over how to freeze a subset of layers and train the remaining layers on a new dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grabbing some data for fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeolite_data = Dataset.from_file(\"data/chabazite.pth.tar\")\n",
    "train, val, test = split_train_validation_test(\n",
    "    zeolite_data, val_size=0.1, test_size=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train, batch_size=BATCH_SIZE, collate_fn=collate_dicts)\n",
    "val_loader = DataLoader(val, batch_size=BATCH_SIZE, collate_fn=collate_dicts)\n",
    "test_loader = DataLoader(test, batch_size=BATCH_SIZE, collate_fn=collate_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model on the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by assessing how well the model predicts energies and forces for these data before we do any fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hexbin(pred, targ, ax, key, scale=\"log\", units: dict = UNITS):\n",
    "    mae = mean_absolute_error(targ, pred)\n",
    "\n",
    "    if scale == \"log\":\n",
    "        pred = np.abs(pred) + 1e-8\n",
    "        targ = np.abs(targ) + 1e-8\n",
    "\n",
    "    lim_min = min(np.min(pred), np.min(targ)) * 1.1\n",
    "    lim_max = max(np.max(pred), np.max(targ)) * 1.1\n",
    "\n",
    "    extent = [lim_min, lim_max, lim_min, lim_max]\n",
    "\n",
    "    hb = ax.hexbin(\n",
    "        pred,\n",
    "        targ,\n",
    "        cmap=\"viridis\",\n",
    "        gridsize=60,\n",
    "        bins=\"log\",\n",
    "        mincnt=1,\n",
    "        edgecolors=None,\n",
    "        linewidths=(0.1,),\n",
    "        xscale=scale,\n",
    "        yscale=scale,\n",
    "        extent=extent,\n",
    "    )\n",
    "\n",
    "    ax.set_xlim(lim_min, lim_max)\n",
    "    ax.set_ylim(lim_min, lim_max)\n",
    "    ax.set_aspect(\"equal\")\n",
    "\n",
    "    ax.plot(\n",
    "        (lim_min, lim_max),\n",
    "        (lim_min, lim_max),\n",
    "        color=\"#000000\",\n",
    "        zorder=-1,\n",
    "        linewidth=0.5,\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel(\"predicted / %s\" % (units[key]), fontsize=12, fontweight=\"bold\")\n",
    "    ax.set_ylabel(\"target / %s\" % (units[key]), fontsize=12, fontweight=\"bold\")\n",
    "\n",
    "    ax.annotate(\n",
    "        \"MAE: %.3f %s\" % (mae, units[key]),\n",
    "        (0.03, 0.95),\n",
    "        xycoords=\"axes fraction\",\n",
    "        fontsize=12,\n",
    "        fontweight=\"bold\",\n",
    "        fontstyle=\"italic\",\n",
    "    )\n",
    "\n",
    "    return ax, hb\n",
    "\n",
    "\n",
    "def stack_cat(item):\n",
    "    try:\n",
    "        out = torch.stack(item, dim=0)\n",
    "    except RuntimeError:\n",
    "        out = torch.cat(item, dim=0)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_fn = loss.build_mse_loss(loss_coef={\"energy\": 0.01, \"energy_grad\": 1})\n",
    "loss_fn = loss.build_mse_loss(loss_coef={\"energy\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results, targets, val_loss = evaluate(nff_mace, test_loader, loss_fn, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax_fig = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# for ax, key in zip(ax_fig, UNITS.keys()):\n",
    "#     pred = stack_cat(results[key]).detach().cpu().numpy().reshape(-1)\n",
    "#     targ = stack_cat(targets[key]).detach().cpu().numpy().reshape(-1)\n",
    "\n",
    "#     plot_hexbin(pred, targ, ax, key, scale=\"linear\")\n",
    "\n",
    "#     ax.set_title(\"%s: %s\" % (\"MACE\", key.upper()), fontsize=14)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance here is pretty bad, but that's the whole reason we're fine-tuning the model. We'll tackle this fine-tuning in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doing the actual fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will freeze the early layers that comprise the learned representations and message passing: `node_embedding` and `interactions` (the `radial_embedding`, `spherical_harmonics`, and `atomic_energies_fn` have no learned parameters). Then, we'll train the remaining layers (`products`, `readouts`, and `scale_shift`) on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing params in layer:  LinearNodeEmbeddingBlock(\n",
      "  (linear): Linear(89x0e -> 128x0e | 11392 weights)\n",
      ")  with  11392  parameters.\n",
      "Freezing params in layer:  ModuleList(\n",
      "  (0): RealAgnosticResidualInteractionBlock(\n",
      "    (linear_up): Linear(128x0e -> 128x0e | 16384 weights)\n",
      "    (conv_tp): TensorProduct(128x0e x 1x0e+1x1o+1x2e+1x3o -> 128x0e+128x1o+128x2e+128x3o | 512 paths | 512 weights)\n",
      "    (conv_tp_weights): FullyConnectedNet[10, 64, 64, 64, 512]\n",
      "    (linear): Linear(128x0e+128x1o+128x2e+128x3o -> 128x0e+128x1o+128x2e+128x3o | 65536 weights)\n",
      "    (skip_tp): FullyConnectedTensorProduct(128x0e x 89x0e -> 128x0e+128x1o | 1458176 paths | 1458176 weights)\n",
      "    (reshape): reshape_irreps()\n",
      "  )\n",
      "  (1): RealAgnosticResidualInteractionBlock(\n",
      "    (linear_up): Linear(128x0e+128x1o -> 128x0e+128x1o | 32768 weights)\n",
      "    (conv_tp): TensorProduct(128x0e+128x1o x 1x0e+1x1o+1x2e+1x3o -> 256x0e+384x1o+384x2e+256x3o | 1280 paths | 1280 weights)\n",
      "    (conv_tp_weights): FullyConnectedNet[10, 64, 64, 64, 1280]\n",
      "    (linear): Linear(256x0e+384x1o+384x2e+256x3o -> 128x0e+128x1o+128x2e+128x3o | 163840 weights)\n",
      "    (skip_tp): FullyConnectedTensorProduct(128x0e+128x1o x 89x0e -> 128x0e | 1458176 paths | 1458176 weights)\n",
      "    (reshape): reshape_irreps()\n",
      "  )\n",
      ")  with  3327232  parameters.\n",
      "Freezing params in layer:  ModuleList(\n",
      "  (0): EquivariantProductBasisBlock(\n",
      "    (symmetric_contractions): SymmetricContraction(\n",
      "      (contractions): ModuleList(\n",
      "        (0): Contraction(\n",
      "          (contractions_weighting): ModuleList(\n",
      "            (0-1): 2 x GraphModule()\n",
      "          )\n",
      "          (contractions_features): ModuleList(\n",
      "            (0-1): 2 x GraphModule()\n",
      "          )\n",
      "          (weights): ParameterList(\n",
      "              (0): Parameter containing: [torch.float64 of size 89x4x128]\n",
      "              (1): Parameter containing: [torch.float64 of size 89x1x128]\n",
      "          )\n",
      "          (graph_opt_main): GraphModule()\n",
      "        )\n",
      "        (1): Contraction(\n",
      "          (contractions_weighting): ModuleList(\n",
      "            (0-1): 2 x GraphModule()\n",
      "          )\n",
      "          (contractions_features): ModuleList(\n",
      "            (0-1): 2 x GraphModule()\n",
      "          )\n",
      "          (weights): ParameterList(\n",
      "              (0): Parameter containing: [torch.float64 of size 89x6x128]\n",
      "              (1): Parameter containing: [torch.float64 of size 89x1x128]\n",
      "          )\n",
      "          (graph_opt_main): GraphModule()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (linear): Linear(128x0e+128x1o -> 128x0e+128x1o | 32768 weights)\n",
      "  )\n",
      "  (1): EquivariantProductBasisBlock(\n",
      "    (symmetric_contractions): SymmetricContraction(\n",
      "      (contractions): ModuleList(\n",
      "        (0): Contraction(\n",
      "          (contractions_weighting): ModuleList(\n",
      "            (0-1): 2 x GraphModule()\n",
      "          )\n",
      "          (contractions_features): ModuleList(\n",
      "            (0-1): 2 x GraphModule()\n",
      "          )\n",
      "          (weights): ParameterList(\n",
      "              (0): Parameter containing: [torch.float64 of size 89x4x128]\n",
      "              (1): Parameter containing: [torch.float64 of size 89x1x128]\n",
      "          )\n",
      "          (graph_opt_main): GraphModule()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (linear): Linear(128x0e -> 128x0e | 16384 weights)\n",
      "  )\n",
      ")  with  1347840  parameters.\n"
     ]
    }
   ],
   "source": [
    "freeze_layers = [\n",
    "    mace_model.node_embedding,\n",
    "    mace_model.interactions,\n",
    "    mace_model.products,\n",
    "]\n",
    "\n",
    "for layer in freeze_layers:\n",
    "    num_params = sum(p.numel() for p in layer.parameters())\n",
    "    print(\n",
    "        \"Freezing params in layer: \",\n",
    "        str(layer),\n",
    "        \" with \",\n",
    "        num_params,\n",
    "        \" parameters.\",\n",
    "    )\n",
    "    for param in layer.parameters():\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will need to set up all the parameters for training. We'll make variables to contain our training metrics, hooks for training, and the optimizer. Then, we'll train the model on the new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metrics = [\n",
    "    metrics.MeanAbsoluteError(\"energy\"),\n",
    "    metrics.MeanAbsoluteError(\"energy_grad\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable_params = filter(lambda p: p.requires_grad, mace_model.parameters())\n",
    "optimizer = Adam(trainable_params, lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_hooks = [\n",
    "#     hooks.MaxEpochHook(10),\n",
    "#     hooks.CSVHook(\n",
    "#         OUTDIR_MACE,\n",
    "#         metrics=train_metrics,\n",
    "#     ),\n",
    "#     hooks.PrintingHook(\n",
    "#         OUTDIR_MACE,\n",
    "#         metrics=train_metrics,\n",
    "#         separator=\" | \",\n",
    "#         time_strf=\"%M:%S\",\n",
    "#         log_memory=False,\n",
    "#     ),\n",
    "#     hooks.ReduceLROnPlateauHook(\n",
    "#         optimizer=optimizer,\n",
    "#         patience=30,\n",
    "#         factor=0.5,\n",
    "#         min_lr=1e-7,\n",
    "#         window_length=1,\n",
    "#         stop_after_min=True,\n",
    "#     ),\n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we pass the model through the `NFFMACEWrapper` so that it can interface with the `nff` package. The wrapper has a `forward` method that takes inputs as `AtomsBatch` objects, translates them to `torch_geometric` objects, and passes them through the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function build_general_loss.<locals>.loss_fn at 0x7fb59c0824c0>\n"
     ]
    }
   ],
   "source": [
    "print(loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = Trainer(\n",
    "    model_path=OUTDIR_MACE,\n",
    "    model=mace_model,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    train_loader=train_loader,\n",
    "    validation_loader=val_loader,\n",
    "    checkpoint_interval=1,\n",
    "    # hooks=train_hooks,\n",
    "    # retain_graph=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1681 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cutoff of invalid type <class 'torch.Tensor'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/miniforge3/envs/nff/lib/python3.9/site-packages/matscipy/neighbours.py:718\u001b[0m, in \u001b[0;36mneighbour_list\u001b[0;34m(quantities, atoms, cutoff, positions, cell, pbc, numbers, cell_origin)\u001b[0m\n\u001b[1;32m    717\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 718\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mffi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mneighbour_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquantities\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell_origin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcell\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpbc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpositions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m                              \u001b[49m\u001b[43m_cutoff\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumbers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mValueError\u001b[0m: object of too small depth for desired array",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[83], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mT\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/NeuralForceField/nff/train/trainer.py:456\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, device, n_epochs)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhooks:\n\u001b[1;32m    454\u001b[0m     hook\u001b[38;5;241m.\u001b[39mon_train_failed(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/NeuralForceField/nff/train/trainer.py:391\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, device, n_epochs)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhooks:\n\u001b[1;32m    389\u001b[0m     hook\u001b[38;5;241m.\u001b[39mon_batch_begin(\u001b[38;5;28mself\u001b[39m, batch)\n\u001b[0;32m--> 391\u001b[0m batch, results, mini_loss, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_and_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcalc_loss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m    393\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misnan(mini_loss):\n\u001b[1;32m    396\u001b[0m     loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m mini_loss\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/NeuralForceField/nff/train/trainer.py:334\u001b[0m, in \u001b[0;36mTrainer.call_and_loss\u001b[0;34m(self, batch, device, calc_loss)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_device \u001b[38;5;241m!=\u001b[39m device:\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto(use_device)\n\u001b[0;32m--> 334\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m calc_loss:\n\u001b[1;32m    336\u001b[0m     mini_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_loss(batch, results)\n",
      "File \u001b[0;32m~/NeuralForceField/nff/train/trainer.py:200\u001b[0m, in \u001b[0;36mTrainer.call_model\u001b[0;34m(self, batch, train)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\n\u001b[0;32m--> 200\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/nff/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/nff/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/NeuralForceField/nff/nn/models/mace.py:177\u001b[0m, in \u001b[0;36mDirectNffScaleMACEWrapper.forward\u001b[0;34m(self, batch, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 177\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_atomsbatch_to_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28mbreakpoint\u001b[39m()\n\u001b[1;32m    179\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mforward(data, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/NeuralForceField/nff/nn/models/mace.py:226\u001b[0m, in \u001b[0;36mDirectNffScaleMACEWrapper.convert_atomsbatch_to_data\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo cell or lattice found in batch\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    219\u001b[0m     config \u001b[38;5;241m=\u001b[39m Configuration(\n\u001b[1;32m    220\u001b[0m         atomic_numbers\u001b[38;5;241m=\u001b[39mnumbers,\n\u001b[1;32m    221\u001b[0m         positions\u001b[38;5;241m=\u001b[39mpositions,\n\u001b[1;32m    222\u001b[0m         cell\u001b[38;5;241m=\u001b[39mcell,\n\u001b[1;32m    223\u001b[0m         pbc\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m    224\u001b[0m     )\n\u001b[1;32m    225\u001b[0m     dataset\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 226\u001b[0m         \u001b[43mAtomicData\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz_table\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mz_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcutoff\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mr_max\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m     )\n\u001b[1;32m    229\u001b[0m data_loader \u001b[38;5;241m=\u001b[39m torch_geometric\u001b[38;5;241m.\u001b[39mdataloader\u001b[38;5;241m.\u001b[39mDataLoader(\n\u001b[1;32m    230\u001b[0m     dataset\u001b[38;5;241m=\u001b[39mdataset,\n\u001b[1;32m    231\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(dataset),\n\u001b[1;32m    232\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    233\u001b[0m     drop_last\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    234\u001b[0m )\n\u001b[1;32m    235\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(data_loader))\u001b[38;5;241m.\u001b[39mto(props[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnxyz\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/miniforge3/envs/nff/lib/python3.9/site-packages/mace/data/atomic_data.py:113\u001b[0m, in \u001b[0;36mAtomicData.from_config\u001b[0;34m(cls, config, z_table, cutoff)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_config\u001b[39m(\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28mcls\u001b[39m, config: Configuration, z_table: AtomicNumberTable, cutoff: \u001b[38;5;28mfloat\u001b[39m\n\u001b[1;32m    112\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAtomicData\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 113\u001b[0m     edge_index, shifts, unit_shifts \u001b[38;5;241m=\u001b[39m \u001b[43mget_neighborhood\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpositions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpositions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcutoff\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcutoff\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpbc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpbc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcell\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m     indices \u001b[38;5;241m=\u001b[39m atomic_numbers_to_indices(config\u001b[38;5;241m.\u001b[39matomic_numbers, z_table\u001b[38;5;241m=\u001b[39mz_table)\n\u001b[1;32m    117\u001b[0m     one_hot \u001b[38;5;241m=\u001b[39m to_one_hot(\n\u001b[1;32m    118\u001b[0m         torch\u001b[38;5;241m.\u001b[39mtensor(indices, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m    119\u001b[0m         num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(z_table),\n\u001b[1;32m    120\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/envs/nff/lib/python3.9/site-packages/mace/data/neighborhood.py:37\u001b[0m, in \u001b[0;36mget_neighborhood\u001b[0;34m(positions, cutoff, pbc, cell, true_self_interaction)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pbc_z:\n\u001b[1;32m     35\u001b[0m     cell[:, \u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m max_positions \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m5\u001b[39m \u001b[38;5;241m*\u001b[39m cutoff \u001b[38;5;241m*\u001b[39m identity[:, \u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m---> 37\u001b[0m sender, receiver, unit_shifts \u001b[38;5;241m=\u001b[39m \u001b[43mneighbour_list\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquantities\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mijS\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpbc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpbc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcell\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpositions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpositions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcutoff\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcutoff\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self_interaction=True,  # we want edges from atom to itself in different periodic images\u001b[39;49;00m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# use_scaled_positions=False,  # positions are not scaled positions\u001b[39;49;00m\n\u001b[1;32m     45\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m true_self_interaction:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;66;03m# Eliminate self-edges that don't cross periodic boundaries\u001b[39;00m\n\u001b[1;32m     49\u001b[0m     true_self_edge \u001b[38;5;241m=\u001b[39m sender \u001b[38;5;241m==\u001b[39m receiver\n",
      "File \u001b[0;32m~/miniforge3/envs/nff/lib/python3.9/site-packages/matscipy/neighbours.py:723\u001b[0m, in \u001b[0;36mneighbour_list\u001b[0;34m(quantities, atoms, cutoff, positions, cell, pbc, numbers, cell_origin)\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    722\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject of too small depth for desired array\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 723\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcutoff of invalid type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(_cutoff)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    724\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[0;31mTypeError\u001b[0m: cutoff of invalid type <class 'torch.Tensor'>"
     ]
    }
   ],
   "source": [
    "T.train(device=DEVICE, n_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try doing the same tests with CHGNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we're going to load the NFF wrapper around the pre-trained CHGNet architecture and try training it the same way as we did with MACE above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHGNet v0.3.0 initialized with 412,525 parameters\n"
     ]
    }
   ],
   "source": [
    "chgnet_nff = CHGNetNFF.load(\"0.3.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.modules of CHGNetNFF(\n",
       "  (composition_model): AtomRef(\n",
       "    (fc): Linear(in_features=94, out_features=1, bias=False)\n",
       "  )\n",
       "  (graph_converter): CrystalGraphConverter(algorithm='fast', atom_graph_cutoff=6, bond_graph_cutoff=3)\n",
       "  (atom_embedding): AtomEmbedding(\n",
       "    (embedding): Embedding(94, 64)\n",
       "  )\n",
       "  (bond_basis_expansion): BondEncoder(\n",
       "    (rbf_expansion_ag): RadialBessel(\n",
       "      (smooth_cutoff): CutoffPolynomial()\n",
       "    )\n",
       "    (rbf_expansion_bg): RadialBessel(\n",
       "      (smooth_cutoff): CutoffPolynomial()\n",
       "    )\n",
       "  )\n",
       "  (bond_embedding): Linear(in_features=31, out_features=64, bias=False)\n",
       "  (bond_weights_ag): Linear(in_features=31, out_features=64, bias=False)\n",
       "  (bond_weights_bg): Linear(in_features=31, out_features=64, bias=False)\n",
       "  (angle_basis_expansion): AngleEncoder(\n",
       "    (fourier_expansion): Fourier()\n",
       "  )\n",
       "  (angle_embedding): Linear(in_features=31, out_features=64, bias=False)\n",
       "  (atom_conv_layers): ModuleList(\n",
       "    (0-3): 4 x AtomConv(\n",
       "      (activation): SiLU()\n",
       "      (twoBody_atom): GatedMLP(\n",
       "        (mlp_core): MLP(\n",
       "          (layers): Sequential(\n",
       "            (0): Linear(in_features=192, out_features=64, bias=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Linear(in_features=64, out_features=64, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (mlp_gate): MLP(\n",
       "          (layers): Sequential(\n",
       "            (0): Linear(in_features=192, out_features=64, bias=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Linear(in_features=64, out_features=64, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (activation): SiLU()\n",
       "        (sigmoid): Sigmoid()\n",
       "        (bn1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (bn2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (mlp_out): MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Dropout(p=0, inplace=False)\n",
       "          (1): Linear(in_features=64, out_features=64, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (bond_conv_layers): ModuleList(\n",
       "    (0-2): 3 x BondConv(\n",
       "      (activation): SiLU()\n",
       "      (twoBody_bond): GatedMLP(\n",
       "        (mlp_core): MLP(\n",
       "          (layers): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=64, bias=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Linear(in_features=64, out_features=64, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (mlp_gate): MLP(\n",
       "          (layers): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=64, bias=True)\n",
       "            (1): SiLU()\n",
       "            (2): Dropout(p=0, inplace=False)\n",
       "            (3): Linear(in_features=64, out_features=64, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (activation): SiLU()\n",
       "        (sigmoid): Sigmoid()\n",
       "        (bn1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (bn2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (mlp_out): MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Dropout(p=0, inplace=False)\n",
       "          (1): Linear(in_features=64, out_features=64, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (angle_layers): ModuleList(\n",
       "    (0-2): 3 x AngleUpdate(\n",
       "      (activation): SiLU()\n",
       "      (twoBody_bond): GatedMLP(\n",
       "        (mlp_core): MLP(\n",
       "          (layers): Sequential(\n",
       "            (0): Dropout(p=0, inplace=False)\n",
       "            (1): Linear(in_features=256, out_features=64, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (mlp_gate): MLP(\n",
       "          (layers): Sequential(\n",
       "            (0): Dropout(p=0, inplace=False)\n",
       "            (1): Linear(in_features=256, out_features=64, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (activation): SiLU()\n",
       "        (sigmoid): Sigmoid()\n",
       "        (bn1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (bn2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (site_wise): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (readout_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "  (pooling): GraphPooling()\n",
       "  (mlp): MLP(\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): SiLU()\n",
       "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (3): SiLU()\n",
       "      (4): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (5): SiLU()\n",
       "      (6): Dropout(p=0, inplace=False)\n",
       "      (7): Linear(in_features=64, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chgnet_nff.modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in [\n",
    "    chgnet_nff.atom_embedding,\n",
    "    chgnet_nff.bond_embedding,\n",
    "    chgnet_nff.angle_embedding,\n",
    "    chgnet_nff.bond_basis_expansion,\n",
    "    chgnet_nff.angle_basis_expansion,\n",
    "    chgnet_nff.atom_conv_layers[:-1],\n",
    "    chgnet_nff.bond_conv_layers,\n",
    "    chgnet_nff.angle_layers,\n",
    "]:\n",
    "    for param in layer.parameters():\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = loss.build_mse_loss(loss_coef={\"energy\": 0.01, \"energy_grad\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable_params = filter(lambda p: p.requires_grad, mace_model.parameters())\n",
    "optimizer = Adam(trainable_params, lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = Trainer(\n",
    "    model_path=OUTDIR_CHGNET,\n",
    "    model=chgnet_nff,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    train_loader=train_loader,\n",
    "    validation_loader=val_loader,\n",
    "    checkpoint_interval=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1681 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 structures imported\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1681 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'atomic_number'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[91], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mT\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/NeuralForceField/nff/train/trainer.py:456\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, device, n_epochs)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhooks:\n\u001b[1;32m    454\u001b[0m     hook\u001b[38;5;241m.\u001b[39mon_train_failed(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/NeuralForceField/nff/train/trainer.py:391\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, device, n_epochs)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhooks:\n\u001b[1;32m    389\u001b[0m     hook\u001b[38;5;241m.\u001b[39mon_batch_begin(\u001b[38;5;28mself\u001b[39m, batch)\n\u001b[0;32m--> 391\u001b[0m batch, results, mini_loss, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_and_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcalc_loss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m    393\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misnan(mini_loss):\n\u001b[1;32m    396\u001b[0m     loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m mini_loss\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/NeuralForceField/nff/train/trainer.py:334\u001b[0m, in \u001b[0;36mTrainer.call_and_loss\u001b[0;34m(self, batch, device, calc_loss)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_device \u001b[38;5;241m!=\u001b[39m device:\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto(use_device)\n\u001b[0;32m--> 334\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m calc_loss:\n\u001b[1;32m    336\u001b[0m     mini_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_loss(batch, results)\n",
      "File \u001b[0;32m~/NeuralForceField/nff/train/trainer.py:200\u001b[0m, in \u001b[0;36mTrainer.call_model\u001b[0;34m(self, batch, train)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\n\u001b[0;32m--> 200\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/nff/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/nff/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/NeuralForceField/nff/nn/models/chgnet.py:49\u001b[0m, in \u001b[0;36mCHGNetNFF.forward\u001b[0;34m(self, data_batch)\u001b[0m\n\u001b[1;32m     47\u001b[0m graphs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_data_batch_to_data(data_batch)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mbreakpoint\u001b[39m()\n\u001b[0;32m---> 49\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mef\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/miniforge3/envs/nff/lib/python3.9/site-packages/chgnet/model/model.py:353\u001b[0m, in \u001b[0;36mCHGNet.forward\u001b[0;34m(self, graphs, task, return_site_energies, return_atom_feas, return_crystal_feas)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get prediction associated with input graphs\u001b[39;00m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;124;03m    graphs (List): a list of CrystalGraphs\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;124;03m    model output (dict).\u001b[39;00m\n\u001b[1;32m    350\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;66;03m# Optionally, make composition model prediction\u001b[39;00m\n\u001b[1;32m    352\u001b[0m comp_energy \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 353\u001b[0m     \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomposition_model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomposition_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraphs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    354\u001b[0m )\n\u001b[1;32m    356\u001b[0m \u001b[38;5;66;03m# Make batched graph\u001b[39;00m\n\u001b[1;32m    357\u001b[0m batched_graph \u001b[38;5;241m=\u001b[39m BatchedGraph\u001b[38;5;241m.\u001b[39mfrom_graphs(\n\u001b[1;32m    358\u001b[0m     graphs,\n\u001b[1;32m    359\u001b[0m     bond_basis_expansion\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbond_basis_expansion,\n\u001b[1;32m    360\u001b[0m     angle_basis_expansion\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mangle_basis_expansion,\n\u001b[1;32m    361\u001b[0m     compute_stress\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m task,\n\u001b[1;32m    362\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/nff/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/nff/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/nff/lib/python3.9/site-packages/chgnet/model/composition_model.py:108\u001b[0m, in \u001b[0;36mAtomRef.forward\u001b[0;34m(self, graphs)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get the energy of a list of CrystalGraphs.\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;124;03m    energy (tensor)\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfitted \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomposition model need to be fitted first!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 108\u001b[0m composition_feas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_assemble_graphs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraphs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_energy(composition_feas)\n",
      "File \u001b[0;32m~/miniforge3/envs/nff/lib/python3.9/site-packages/chgnet/model/composition_model.py:180\u001b[0m, in \u001b[0;36mAtomRef._assemble_graphs\u001b[0;34m(self, graphs)\u001b[0m\n\u001b[1;32m    177\u001b[0m composition_feas \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m graph \u001b[38;5;129;01min\u001b[39;00m graphs:\n\u001b[1;32m    179\u001b[0m     composition_fea \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbincount(\n\u001b[0;32m--> 180\u001b[0m         \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43matomic_number\u001b[49m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, minlength\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_num_elements\n\u001b[1;32m    181\u001b[0m     )\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_intensive:\n\u001b[1;32m    183\u001b[0m         n_atom \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39matomic_number\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'atomic_number'"
     ]
    }
   ],
   "source": [
    "T.train(device=DEVICE, n_epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
