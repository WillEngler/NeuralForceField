{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Neural Force Field with SIGOPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter Notebook is an introduction in using the `nff` package together with the hyperparameter optimization tool SIGOPT. This tutorial uses the same code and dataset as `01_training`, thus if you have not done that one, it is highly recommended to check it out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the `nff` package has been installed, we start by importing all dependencies for this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '/home/jurgis/NeuralForceField/') # path towards the NFF folder for loading the module\n",
    "\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from nff.data import Dataset, split_train_validation_test, collate_dicts, to_tensor\n",
    "from nff.train import Trainer, get_trainer, get_model, load_model, loss, hooks, metrics, evaluate\n",
    "\n",
    "from sigopt import Connection\n",
    "from sigopt.examples import franke_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the relevant data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we usually work with the database, we can pack their information in a class `Dataset`, which is a subclass of `torch.utils.data.Dataset`. It basically wraps information on the atomic numbers, energies, forces and SMILES strings for each one of the geometries. In this example, we already have a pre-compiled `Dataset` to be used. We start by loading this file and creating three slices of the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_file('./data/dataset.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = split_train_validation_test(dataset, val_size=0.2, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `nff` code interfaces with the `graphbuilder` module through a git submodule in the repository. `graphbuilder` provides methods to create batches of graphs. In `nff`, we interface that through a custom dataloader called `\n",
    "GraphLoader`. Here, we create one loader for each one of the slices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train, batch_size=50, collate_fn=collate_dicts)\n",
    "val_loader = DataLoader(val, batch_size=50, collate_fn=collate_dicts)\n",
    "test_loader = DataLoader(test, batch_size=50, collate_fn=collate_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path aleardy exists\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "today = date.today()\n",
    "variable = str(today.day) + str(today.month) + str(today.year)\n",
    "path = '/home/jurgis/NeuralForceField/tutorials/sigopt/{}/'.format(variable)\n",
    "if os.path.isdir(path) == False:\n",
    "    os.mkdir(path)\n",
    "else:\n",
    "    print('Path aleardy exists')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`SIGOPT` is a standardized, scalable, optimization platform and API designed to unlock the potential of your modeling pipelines. This fully agnostic software solution accelerates, amplifies, and scales the model development process.\n",
    "\n",
    "For registering on the website you need an invitation from someone in the lab.\n",
    "\n",
    "Short introduction into the tools is given at https://app.sigopt.com/getstarted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = Connection(client_token=\"JQJLZYNHOWKBUXWMYBZFKRKHURZAZRIQWERJSBKWZUBODXEQ\")\n",
    "\n",
    "experiment = conn.experiments().create(\n",
    "    name='tutorial ',\n",
    "    metrics=[dict(name='energy', objective='minimize')],\n",
    "    parameters=[\n",
    "        dict(name='n_atom_basis', type='int', bounds=dict(min=120, max=360)),\n",
    "        dict(name='n_filters', type='int', bounds=dict(min=120, max=360)),\n",
    "        dict(name='n_gaussians', type='int', bounds=dict(min=10, max=70)),\n",
    "        dict(name='n_convolutions', type='int', bounds=dict(min=1, max=10)),\n",
    "        dict(name='cutoff', type='double', bounds=dict(min=1.0, max=10.0)),\n",
    "    ],\n",
    "    observation_budget = 10, # how many iterations to run for the optimization\n",
    ")\n",
    "\n",
    "DEVICE = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model creation\n",
    "\n",
    "Creating the model with `SIGOPT` is very similar to that of `nff`, one just wraps up the model part in a function and determines the optimization variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(assignments, suggestion_id, i = 0):\n",
    "    params = dict()\n",
    "    params['n_atom_basis'] = assignments['n_atom_basis']\n",
    "    params['n_filters'] = assignments['n_filters'] \n",
    "    params['n_gaussians'] = assignments['n_gaussians'] \n",
    "    params['n_convolutions'] = assignments['n_convolutions'] \n",
    "    params['cutoff'] = assignments['cutoff']\n",
    "    params['trainable_gauss'] = True \n",
    "\n",
    "    print(params)\n",
    "    \n",
    "    model = get_model(params)\n",
    "\n",
    "    loss_fn = loss.build_mse_loss(loss_coef={'energy': 0.01, 'energy_grad': 1})\n",
    "\n",
    "    trainable_params = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optimizer = Adam(trainable_params, lr=3e-4)\n",
    "\n",
    "    train_metrics = [\n",
    "        metrics.MeanAbsoluteError('energy'),\n",
    "        metrics.MeanAbsoluteError('energy_grad')\n",
    "    ]\n",
    "    \n",
    "    OUTDIR = path + str(suggestion_id)\n",
    "    \n",
    "    train_hooks = [\n",
    "        hooks.MaxEpochHook(100),\n",
    "        hooks.CSVHook(\n",
    "            OUTDIR,\n",
    "            metrics=train_metrics,\n",
    "        ),\n",
    "        hooks.PrintingHook(\n",
    "            OUTDIR,\n",
    "            metrics=train_metrics,\n",
    "            separator = ' | ',\n",
    "            time_strf='%M:%S'\n",
    "        ),\n",
    "        hooks.ReduceLROnPlateauHook(\n",
    "            optimizer=optimizer,\n",
    "            patience=30,\n",
    "            factor=0.5,\n",
    "            min_lr=1e-7,\n",
    "            window_length=1,\n",
    "            stop_after_min=True\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    T = Trainer(\n",
    "        model_path=OUTDIR,\n",
    "        model=model,\n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optimizer,\n",
    "        train_loader=train_loader,\n",
    "        validation_loader=val_loader,\n",
    "        checkpoint_interval=1,\n",
    "        hooks=train_hooks\n",
    "    )\n",
    "\n",
    "    T.train(device=DEVICE, n_epochs=10)\n",
    "    \n",
    "    _, _, val_loss = evaluate(T.get_best_model(), test_loader, loss_fn, device=DEVICE)\n",
    "    \n",
    "    return val_loss\n",
    "\n",
    "def evaluate_model(assignments, i, suggestion_id):\n",
    "    value = create_model(assignments=assignments, i=i, suggestion_id=suggestion_id)\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_atom_basis': 321, 'n_filters': 142, 'n_gaussians': 19, 'n_convolutions': 10, 'cutoff': 4.096756541252811, 'trainable_gauss': True}\n",
      " Time | Epoch | Learning rate | Train loss | Validation loss | MAE_energy | MAE_energy_grad | GPU Memory (MB)\n",
      "20:19 |     1 |     3.000e-04 |     0.0000 |        283.4901 |    11.7943 |         11.6579 |             453\n",
      "20:20 |     2 |     3.000e-04 |     0.0000 |        130.1209 |     8.9165 |          8.5261 |             453\n",
      "20:21 |     3 |     3.000e-04 |     0.0000 |         79.9222 |     6.2299 |          6.4821 |             453\n",
      "20:23 |     4 |     3.000e-04 |     0.0000 |         53.2885 |     3.1344 |          5.3414 |             453\n",
      "20:24 |     5 |     3.000e-04 |     0.0000 |         39.3358 |     6.5732 |          4.4261 |             453\n",
      "20:26 |     6 |     3.000e-04 |     0.0000 |         36.3659 |     3.2553 |          4.3964 |             453\n",
      "20:27 |     7 |     3.000e-04 |     0.0000 |         35.6962 |     4.8125 |          4.3751 |             453\n",
      "20:29 |     8 |     3.000e-04 |     0.0000 |         32.6817 |     1.6940 |          4.2068 |             453\n",
      "20:30 |     9 |     3.000e-04 |     0.0000 |         25.7763 |     3.2188 |          3.6219 |             453\n",
      "20:32 |    10 |     3.000e-04 |     0.0000 |         26.0324 |     1.3392 |          3.6974 |             453\n",
      "26.064716339111328\n",
      "{'n_atom_basis': 280, 'n_filters': 209, 'n_gaussians': 22, 'n_convolutions': 7, 'cutoff': 7.666113300116235, 'trainable_gauss': True}\n",
      " Time | Epoch | Learning rate | Train loss | Validation loss | MAE_energy | MAE_energy_grad | GPU Memory (MB)\n",
      "20:35 |     1 |     3.000e-04 |     0.0000 |        619.8860 |     5.8390 |         18.3944 |             453\n",
      "20:36 |     2 |     3.000e-04 |     0.0000 |        397.5322 |    54.2177 |         14.3350 |             453\n",
      "20:37 |     3 |     3.000e-04 |     0.0000 |        265.8249 |    42.8442 |         11.7216 |             453\n",
      "20:38 |     4 |     3.000e-04 |     0.0000 |        163.7850 |     9.9212 |          9.5620 |             453\n",
      "20:39 |     5 |     3.000e-04 |     0.0000 |        133.8858 |     2.0631 |          8.8210 |             453\n",
      "20:41 |     6 |     3.000e-04 |     0.0000 |        107.9684 |     1.8216 |          7.8682 |             453\n",
      "20:42 |     7 |     3.000e-04 |     0.0000 |         99.0351 |    11.4821 |          7.4557 |             453\n",
      "20:43 |     8 |     3.000e-04 |     0.0000 |         68.7988 |     1.8226 |          6.1264 |             453\n",
      "20:44 |     9 |     3.000e-04 |     0.0000 |         68.3335 |    13.6514 |          6.0571 |             453\n",
      "20:45 |    10 |     3.000e-04 |     0.0000 |         70.6759 |    18.6573 |          6.3005 |             453\n",
      "67.51884746551514\n",
      "{'n_atom_basis': 210, 'n_filters': 277, 'n_gaussians': 64, 'n_convolutions': 4, 'cutoff': 8.885284576944114, 'trainable_gauss': True}\n",
      " Time | Epoch | Learning rate | Train loss | Validation loss | MAE_energy | MAE_energy_grad | GPU Memory (MB)\n",
      "20:48 |     1 |     3.000e-04 |     0.0000 |        536.9511 |    18.4251 |         16.5379 |             453\n",
      "20:49 |     2 |     3.000e-04 |     0.0000 |        239.2335 |    11.8282 |         10.8562 |             453\n",
      "20:50 |     3 |     3.000e-04 |     0.0000 |        133.8867 |     4.2107 |          8.4696 |             453\n",
      "20:50 |     4 |     3.000e-04 |     0.0000 |         92.1270 |     3.5949 |          6.9842 |             453\n",
      "20:51 |     5 |     3.000e-04 |     0.0000 |         77.6769 |     3.1909 |          6.3790 |             453\n",
      "20:52 |     6 |     3.000e-04 |     0.0000 |         60.1921 |     1.9659 |          5.4966 |             453\n",
      "20:53 |     7 |     3.000e-04 |     0.0000 |         49.5295 |     3.9031 |          4.9720 |             453\n",
      "20:54 |     8 |     3.000e-04 |     0.0000 |         47.3742 |     4.3830 |          4.9345 |             453\n",
      "20:55 |     9 |     3.000e-04 |     0.0000 |         33.8834 |     1.2360 |          4.0624 |             453\n",
      "20:55 |    10 |     3.000e-04 |     0.0000 |         30.3110 |     1.2640 |          3.8375 |             453\n",
      "29.115456581115723\n",
      "{'n_atom_basis': 142, 'n_filters': 250, 'n_gaussians': 41, 'n_convolutions': 2, 'cutoff': 6.133164443460488, 'trainable_gauss': True}\n",
      " Time | Epoch | Learning rate | Train loss | Validation loss | MAE_energy | MAE_energy_grad | GPU Memory (MB)\n",
      "20:57 |     1 |     3.000e-04 |     0.0000 |        708.0251 |     4.5377 |         19.6694 |             453\n",
      "20:58 |     2 |     3.000e-04 |     0.0000 |        529.4096 |    32.7195 |         16.3003 |             453\n",
      "20:58 |     3 |     3.000e-04 |     0.0000 |        333.4508 |     6.6683 |         12.7120 |             453\n",
      "20:59 |     4 |     3.000e-04 |     0.0000 |        203.4182 |     4.0590 |         10.2028 |             453\n",
      "20:59 |     5 |     3.000e-04 |     0.0000 |        132.5145 |     3.4847 |          8.3481 |             453\n",
      "21:00 |     6 |     3.000e-04 |     0.0000 |        103.1410 |     5.4466 |          7.4197 |             453\n",
      "21:00 |     7 |     3.000e-04 |     0.0000 |         83.0860 |     7.6399 |          6.5065 |             453\n",
      "21:01 |     8 |     3.000e-04 |     0.0000 |         69.3769 |     5.4534 |          5.8133 |             453\n",
      "21:01 |     9 |     3.000e-04 |     0.0000 |         61.5883 |     1.4677 |          5.4928 |             453\n",
      "21:02 |    10 |     3.000e-04 |     0.0000 |         55.1571 |     1.9023 |          5.1711 |             453\n",
      "54.38020992279053\n",
      "{'n_atom_basis': 263, 'n_filters': 327, 'n_gaussians': 56, 'n_convolutions': 6, 'cutoff': 2.057090133522175, 'trainable_gauss': True}\n",
      " Time | Epoch | Learning rate | Train loss | Validation loss | MAE_energy | MAE_energy_grad | GPU Memory (MB)\n",
      "21:05 |     1 |     3.000e-04 |     0.0000 |        342.2550 |     9.2400 |         12.8024 |             560\n",
      "21:06 |     2 |     3.000e-04 |     0.0000 |        202.4344 |    15.4852 |          9.9905 |             560\n",
      "21:07 |     3 |     3.000e-04 |     0.0000 |        152.3225 |    11.8812 |          8.5871 |             560\n",
      "21:08 |     4 |     3.000e-04 |     0.0000 |        120.9660 |     6.3341 |          7.6326 |             560\n",
      "21:09 |     5 |     3.000e-04 |     0.0000 |         96.6658 |     1.7313 |          6.8320 |             560\n",
      "21:11 |     6 |     3.000e-04 |     0.0000 |         87.5712 |     1.7450 |          6.4782 |             560\n",
      "21:12 |     7 |     3.000e-04 |     0.0000 |         78.3571 |     1.8198 |          6.0732 |             560\n",
      "21:13 |     8 |     3.000e-04 |     0.0000 |         70.9779 |     2.1317 |          5.7198 |             560\n",
      "21:14 |     9 |     3.000e-04 |     0.0000 |         66.6319 |     1.9331 |          5.5194 |             560\n",
      "21:16 |    10 |     3.000e-04 |     0.0000 |         63.4233 |     1.8848 |          5.3861 |             560\n",
      "92.8403730392456\n",
      "{'n_atom_basis': 347, 'n_filters': 120, 'n_gaussians': 17, 'n_convolutions': 10, 'cutoff': 1.7544598955502178, 'trainable_gauss': True}\n",
      " Time | Epoch | Learning rate | Train loss | Validation loss | MAE_energy | MAE_energy_grad | GPU Memory (MB)\n",
      "21:19 |     1 |     3.000e-04 |     0.0000 |        304.9000 |    17.0306 |         12.5191 |             560\n",
      "21:20 |     2 |     3.000e-04 |     0.0000 |        157.0503 |     7.1406 |          9.0553 |             560\n",
      "21:22 |     3 |     3.000e-04 |     0.0000 |        135.8299 |    11.2444 |          8.3037 |             560\n",
      "21:23 |     4 |     3.000e-04 |     0.0000 |        112.4559 |     3.5512 |          7.5476 |             560\n",
      "21:25 |     5 |     3.000e-04 |     0.0000 |        100.2349 |     1.9952 |          7.0620 |             560\n",
      "21:26 |     6 |     3.000e-04 |     0.0000 |         93.9196 |     1.8192 |          6.8238 |             560\n",
      "21:28 |     7 |     3.000e-04 |     0.0000 |         86.1942 |     2.2947 |          6.4713 |             560\n",
      "21:29 |     8 |     3.000e-04 |     0.0000 |         78.6269 |     2.1406 |          6.1889 |             560\n",
      "21:30 |     9 |     3.000e-04 |     0.0000 |         75.8593 |     1.6284 |          6.1064 |             560\n",
      "21:32 |    10 |     3.000e-04 |     0.0000 |         72.0609 |     1.6161 |          6.0359 |             560\n",
      "71.16851615905762\n",
      "{'n_atom_basis': 244, 'n_filters': 144, 'n_gaussians': 25, 'n_convolutions': 9, 'cutoff': 4.217500494182863, 'trainable_gauss': True}\n",
      " Time | Epoch | Learning rate | Train loss | Validation loss | MAE_energy | MAE_energy_grad | GPU Memory (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:35 |     1 |     3.000e-04 |     0.0000 |        326.3916 |    25.3239 |         12.5923 |             560\n",
      "21:36 |     2 |     3.000e-04 |     0.0000 |        122.4115 |     1.7842 |          8.2101 |             560\n",
      "21:38 |     3 |     3.000e-04 |     0.0000 |         69.9200 |     5.3672 |          5.9703 |             560\n",
      "21:39 |     4 |     3.000e-04 |     0.0000 |         49.5380 |     1.3919 |          4.9472 |             560\n",
      "21:40 |     5 |     3.000e-04 |     0.0000 |         37.6265 |     1.1964 |          4.3236 |             560\n",
      "21:42 |     6 |     3.000e-04 |     0.0000 |         31.4068 |     0.9466 |          3.9467 |             560\n",
      "21:43 |     7 |     3.000e-04 |     0.0000 |         27.5487 |     0.9138 |          3.7058 |             560\n",
      "21:44 |     8 |     3.000e-04 |     0.0000 |         24.4636 |     0.8747 |          3.5191 |             560\n",
      "21:46 |     9 |     3.000e-04 |     0.0000 |         21.5951 |     1.0873 |          3.3074 |             560\n",
      "21:47 |    10 |     3.000e-04 |     0.0000 |         20.2836 |     2.2640 |          3.1730 |             560\n",
      "19.593333959579468\n",
      "{'n_atom_basis': 291, 'n_filters': 134, 'n_gaussians': 34, 'n_convolutions': 10, 'cutoff': 5.07583637607727, 'trainable_gauss': True}\n",
      " Time | Epoch | Learning rate | Train loss | Validation loss | MAE_energy | MAE_energy_grad | GPU Memory (MB)\n",
      "21:51 |     1 |     3.000e-04 |     0.0000 |        236.5253 |     3.2344 |         11.0515 |             560\n",
      "21:52 |     2 |     3.000e-04 |     0.0000 |        116.2597 |     3.0181 |          8.2316 |             560\n",
      "21:54 |     3 |     3.000e-04 |     0.0000 |         66.6638 |     8.1163 |          5.8358 |             560\n",
      "21:55 |     4 |     3.000e-04 |     0.0000 |         48.3204 |     5.7463 |          4.9526 |             560\n",
      "21:57 |     5 |     3.000e-04 |     0.0000 |         35.1462 |     1.0831 |          4.2194 |             560\n",
      "21:58 |     6 |     3.000e-04 |     0.0000 |         29.3827 |     1.5186 |          3.8368 |             560\n",
      "22:00 |     7 |     3.000e-04 |     0.0000 |         24.5671 |     0.9442 |          3.4724 |             560\n",
      "22:01 |     8 |     3.000e-04 |     0.0000 |         23.1901 |     0.8482 |          3.4127 |             560\n",
      "22:03 |     9 |     3.000e-04 |     0.0000 |         21.5972 |     0.8574 |          3.3408 |             560\n",
      "22:05 |    10 |     3.000e-04 |     0.0000 |         17.7502 |     1.0266 |          2.9880 |             560\n",
      "17.45719599723816\n",
      "{'n_atom_basis': 262, 'n_filters': 120, 'n_gaussians': 13, 'n_convolutions': 10, 'cutoff': 5.5695631726239085, 'trainable_gauss': True}\n",
      " Time | Epoch | Learning rate | Train loss | Validation loss | MAE_energy | MAE_energy_grad | GPU Memory (MB)\n",
      "22:08 |     1 |     3.000e-04 |     0.0000 |        612.6368 |    19.2417 |         18.2198 |             560\n",
      "22:09 |     2 |     3.000e-04 |     0.0000 |        539.3897 |    39.6556 |         17.3803 |             560\n",
      "22:10 |     3 |     3.000e-04 |     0.0000 |        338.7987 |    26.0685 |         13.3842 |             560\n",
      "22:12 |     4 |     3.000e-04 |     0.0000 |        345.4162 |    27.4647 |         13.6052 |             560\n",
      "22:13 |     5 |     3.000e-04 |     0.0000 |        261.9044 |    43.9158 |         11.7459 |             560\n",
      "22:15 |     6 |     3.000e-04 |     0.0000 |        232.5264 |    22.4414 |         11.4125 |             560\n",
      "22:16 |     7 |     3.000e-04 |     0.0000 |        198.7772 |    50.4447 |          9.7795 |             560\n",
      "22:17 |     8 |     3.000e-04 |     0.0000 |        180.9250 |    23.7776 |         10.2881 |             560\n",
      "22:19 |     9 |     3.000e-04 |     0.0000 |        139.9081 |    11.7580 |          9.0399 |             560\n",
      "22:20 |    10 |     3.000e-04 |     0.0000 |        121.3271 |    11.0664 |          8.3433 |             560\n",
      "118.81618118286133\n",
      "{'n_atom_basis': 360, 'n_filters': 163, 'n_gaussians': 32, 'n_convolutions': 9, 'cutoff': 5.276362915426441, 'trainable_gauss': True}\n",
      " Time | Epoch | Learning rate | Train loss | Validation loss | MAE_energy | MAE_energy_grad | GPU Memory (MB)\n",
      "22:23 |     1 |     3.000e-04 |     0.0000 |        210.4451 |    17.1624 |         10.5974 |             560\n",
      "22:25 |     2 |     3.000e-04 |     0.0000 |        104.2800 |    12.2337 |          7.6121 |             560\n",
      "22:26 |     3 |     3.000e-04 |     0.0000 |         66.7684 |     4.3601 |          6.0433 |             560\n",
      "22:27 |     4 |     3.000e-04 |     0.0000 |         51.9315 |     1.1276 |          5.2507 |             560\n",
      "22:29 |     5 |     3.000e-04 |     0.0000 |         38.9679 |     1.6568 |          4.4847 |             560\n",
      "22:30 |     6 |     3.000e-04 |     0.0000 |         30.3617 |     0.9263 |          3.8653 |             560\n",
      "22:32 |     7 |     3.000e-04 |     0.0000 |         26.8384 |     1.0234 |          3.6787 |             560\n",
      "22:33 |     8 |     3.000e-04 |     0.0000 |         23.9534 |     1.3205 |          3.4399 |             560\n",
      "22:35 |     9 |     3.000e-04 |     0.0000 |         21.6737 |     0.9563 |          3.2842 |             560\n",
      "22:36 |    10 |     3.000e-04 |     0.0000 |         22.4154 |     1.3646 |          3.4382 |             560\n",
      "21.594026565551758\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "\n",
    "while experiment.progress.observation_count < experiment.observation_budget:\n",
    "\n",
    "    suggestion = conn.experiments(experiment.id).suggestions().create()\n",
    "\n",
    "\n",
    "    value = evaluate_model(assignments=suggestion.assignments, i=i, suggestion_id=suggestion.id)\n",
    "    print (value)\n",
    "\n",
    "    conn.experiments(experiment.id).observations().create(\n",
    "      suggestion=suggestion.id,\n",
    "      value=value,\n",
    "    )\n",
    "\n",
    "\n",
    "    experiment = conn.experiments(experiment.id).fetch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After the model finishes, all the results are viewable on SIGOPT website for data clarification"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nff]",
   "language": "python",
   "name": "conda-env-nff-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
