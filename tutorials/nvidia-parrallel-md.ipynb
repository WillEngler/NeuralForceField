{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Inferences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter Notebook shows how the `nff` package interfaces with the Atomistic Simulation Environment (ASE). We assume the user went through tutorial `01_training`, so we can load the pretrained models without having to train them again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, importing the dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from ase import Atoms\n",
    "from ase.md.verlet import VelocityVerlet\n",
    "\n",
    "import nff\n",
    "\n",
    "from nff.md.nve import Dynamics\n",
    "from nff.data import Dataset\n",
    "from nff.io.ase import NeuralFF, AtomsBatch\n",
    "from nff.train import load_model, evaluate\n",
    "import nff.utils.constants as const\n",
    "from ase import units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the relevant data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We reload the dataset and create a `GraphLoader` as we did last time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_file('data/dataset.pth.tar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Atoms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we can create an `Atoms` object from any element of the dataset. Let's take the first one, for simplicity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "props = dataset[0].copy()\n",
    "atoms = AtomsBatch(positions=props['nxyz'][:, 1:], numbers=props['nxyz'][:, 0], props=props)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load trained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we load two models, the idea for ensembled approach would be to evaluate the same batch twice with different models to bound the uncertainity for inference purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nff_ase_1 = NeuralFF.from_file('models/cco_1/', device=1)\n",
    "nff_ase_2 = NeuralFF.from_file('models/cco_2/', device=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get batches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nff.utils.cuda import batch_to\n",
    "\n",
    "batch = batch_to(atoms.get_batch(), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "force computed from model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  2.6625, -11.7257,  -1.6760],\n",
       "        [-10.9157,  14.8093,   8.4685],\n",
       "        [-14.1403,   0.8944,   6.1563],\n",
       "        [  0.0431,   2.2324,   4.9156],\n",
       "        [  1.2007,   0.6308,  -4.7388],\n",
       "        [  6.2475,  -5.7065,   6.2277],\n",
       "        [  8.9826,  -8.6119,  -3.2076],\n",
       "        [ -1.0577,   4.6916, -10.8629],\n",
       "        [  6.9773,   2.7857,  -5.2829]], device='cuda:1',\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nff_ase_1.model(batch)['energy_grad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  4.8635, -11.6434,  -1.4136],\n",
       "        [-15.7632,  14.9333,   8.9940],\n",
       "        [-15.3593,   1.0160,   6.6080],\n",
       "        [  0.3149,   2.3005,   4.9099],\n",
       "        [  0.6989,   0.7217,  -4.4088],\n",
       "        [  6.7211,  -6.1006,   7.3934],\n",
       "        [  9.8623, -10.2740,  -4.3793],\n",
       "        [ -0.6546,   5.9508, -11.6523],\n",
       "        [  9.3164,   3.0958,  -6.0514]], device='cuda:1',\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nff_ase_2.model(batch)['energy_grad']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# And we want to take the average of the output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal: how to evaluate on the same data with several models?\\"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nff] *",
   "language": "python",
   "name": "conda-env-nff-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
